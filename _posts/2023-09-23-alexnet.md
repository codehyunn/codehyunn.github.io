---
title: "[AlexNet] ImageNet Classification with Deep Convolutional Neural Networks"
header:
  #image: /assets/images/page-header-image.png
  #og_image: /assets/images/page-header-og-image.png
categories:
  - Paper-Review
tags:
  - paper
  - review
  - alexnet
last_modified_at: 2023-09-23
---
AlexNetì— ëŒ€í•œ ë…¼ë¬¸ì´ë‹¤. ë…¼ë¬¸ ë§í¬ëŠ” [ì—¬ê¸°](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) ğŸ‘€ğŸª„<br>
ìœ ëª…í•œ ë…¼ë¬¸ì´ì§€ë§Œ, ì œëŒ€ë¡œ ì½ì–´ë³¸ ê¸°ì–µì´ ì—†ì–´ì„œ ì´ë²ˆì— ì½ê³  ì •ë¦¬í•´ë´¤ë‹¤.

## | Introduction

ë¬¼ì²´ ì¸ì‹ì—ì„œ ì´ì „ê¹Œì§€ì˜ ëª¨ë¸ë“¤ì€ ì ì€ ë°ì´í„° ì…‹ì„ í™œìš©í•œ ê°„ë‹¨í•œ í…ŒìŠ¤í¬ì— ëŒ€í•´ ì˜ ì‘ë™í•˜ëŠ” ëª¨ìŠµì„ ë³´ì˜€ë‹¤. í•˜ì§€ë§Œ í˜„ì‹¤ì˜ ë¬¸ì œëŠ” ì´ë³´ë‹¤ ë” ë³µì¡í•˜ê¸° ë•Œë¬¸ì— ë” í° ë°ì´í„° ì…‹ê³¼ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ê°€ì§„ ëª¨ë¸ì´ í•„ìš”í–ˆë‹¤. 

ëª¨ë¸ì€ ë” í° í•™ìŠµ ëŠ¥ë ¥ê³¼ ì‚¬ì „ ì§€ì‹ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•˜ëŠ”ë°, ì´ ì¡°ê±´ì— ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì´ ë°”ë¡œ `Convolutional Neural Networks (CNNs)`ì´ë‹¤. CNNì€ ë ˆì´ì–´ì˜ ê¹Šì´ë‚˜ ë„ˆë¹„ì— ë”°ë¼ì„œ í•™ìŠµ ëŠ¥ë ¥ì„ ì¡°ì ˆí•  ìˆ˜ ìˆìœ¼ë©°, ê¸°ì¡´ Feed-forward Neural Networksì— ë¹„í•´ ë” ì ì€ connectionê³¼ íŒŒë¼ë¯¸í„°ë§Œìœ¼ë¡œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. í•˜ì§€ë§Œ CNNì— ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì ìš©í•˜ëŠ” ê²ƒì€ ë¹„ìš© ë¬¸ì œê°€ ë°œìƒí–ˆëŠ”ë°, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” GPU ë³‘ë ¬ í•™ìŠµìœ¼ë¡œ í•´ë‹¹ ë¬¸ì œë¥¼ í•´ê²°í–ˆë‹¤.

## | Dataset

ImageNetì˜ Subsetìœ¼ë¡œ êµ¬ì„±ëœ ILSVRC-2010 ë°ì´í„° ì…‹ì„ ì£¼ë¡œ ì‚¬ìš©í–ˆë‹¤.

ì…ë ¥ ì°¨ì›ì„ ì¼ì •í•˜ê²Œ ë§ì¶”ê¸° ìœ„í•´ ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ 256x256ë¡œ í†µì¼í•˜ì˜€ê³ , ì „ì²´ í”½ì…€ì— ëŒ€í•´ í‰ê·  ê°’ì„ ëºŒìœ¼ë¡œì¨ centered ëœ í”½ì…€ ê°’ìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í–ˆë‹¤.

## | Architecture

### Overall Architecture

![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/7dd979c5-2b8c-49c0-bfe9-239716fa1d77){: .align-center}
    
ì´ 8ê°œì˜ layer(5ê°œì˜ convolution layerì™€ 3ê°œì˜ fully connected layer)ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©° ë³¸ ë…¼ë¬¸ì—ì„œ ì„¤ëª…í•œ ë ˆì´ì–´ ë³„ íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

| ë ˆì´ì–´ | íŠ¹ì§• |
| ----------- | --------------- |
| Layer 1       | input : 224 x 224 x 3 <br> kernel : 11 x 11 x 3 (96ê°œ, stride : 4) <br> Activation fn : ReLU <br> Response Normalization, Overlapping pooling |
| Layer 2       | kernel : 5 x 5 x 48 (256ê°œ) <br> Activation fn : ReLU <br> Response Normalization, Overlapping pooling |
| Layer 3       | kernel : 3 x 3 x 256 (384ê°œ) <br> Activation fn : ReLU |
| Layer 4       | kernel : 3 x 3 x 192 (384ê°œ) <br> Activation fn : ReLU |
| Layer 5       | kernel : 3 x 3 x 192 (256ê°œ) <br> Activation fn : ReLU <br> Overlapping pooling |
| Layer 6 (FC layer) | neuron : 4096ê°œ <br> Activation fn : ReLU |
| Layer 7 (FC layer) | neuron : 4096ê°œ <br> Activation fn : ReLU |
| Layer 8 (FC layer) | Activation fn : softmax <br> output : 1000 | <br>

### ReLU Nonlinearity

![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/e150e747-85b9-4318-9e2a-1dfd131edb5b){: .align-center}


Non-saturating nonlinearity í•¨ìˆ˜(ReLU)ê°€ Saturating nonlinearity í•¨ìˆ˜(sigmoid, tanh ë“±)ì— ë¹„í•´ í•™ìŠµ ì†ë„ê°€ ë¹ ë¥´ë‹¤. ê·¸ë˜ì„œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ê±°ëŒ€í•œ ëª¨ë¸ê³¼ ë°ì´í„° ì…‹ì— ëŒ€í•´ì„œë„ ë¹ ë¥¸ í•™ìŠµì´ ê°€ëŠ¥í•œ ReLUë¥¼ ì‚¬ìš©í–ˆë‹¤.

> **Saturating?** <br>
Saturatingì€ í•¨ìˆ˜ê°€ ì–‘/ìŒì˜ ë¬´í•œëŒ€ë¡œ ê°ˆìˆ˜ë¡ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.
> <br>

### Training on Multiple GPUs
    
ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ë‘ GPUë¥¼ ë³‘ë ¬í™”í•˜ì—¬ í•™ìŠµí–ˆë‹¤. ê° GPUì—ëŠ” ì»¤ë„(í˜¹ì€ ë‰´ëŸ°)ì˜ ì ˆë°˜ì´ ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ë‹¤. ê·¸ë˜ì„œ ë‘ GPUëŠ” íŠ¹ì • ë ˆì´ì–´ì—ì„œë§Œ communicate í•  ìˆ˜ ìˆë‹¤ëŠ” íŠ¹ì§•ì„ ê°€ì§„ë‹¤.
<br>

### Local Response Normalization
    
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/4f5b65af-a0f5-4f47-a086-3d5b064eb1f2){:.align-center}

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì¼ë°˜í™”(generatlization)ì„ ë•ëŠ” Local normalizationì„ ì‚¬ìš©í•œë‹¤. Local normalization ì€ ì¼ë¶€ layerì— ëŒ€í•´ ReLU ì´í›„ ì ìš©í•˜ë©°, local contrast normalizationê³¼ ë‹¬ë¦¬ mean subtract ê³¼ì •ì´ ìˆë‹¤ëŠ” íŠ¹ì§•ì„ ì§€ë‹Œë‹¤.

> **Input normalizationì´ í•„ìš”í•˜ì§€ ì•Šì€ ì´ìœ ?** <br>
Input normalizaitonì€ ë³´í†µ ìˆ˜ë ´ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì´ì§€ë§Œ ReLUëŠ” non-saturating nonlinearity í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì´ë‹¤.
> <br>

### Overlapping Pooling
    
CNNì˜ Pooling layerëŠ” ê°™ì€ ì»¤ë„ë§µ ì•ˆ, ì¸ì ‘í•œ ë‰´ëŸ°ë“¤ì˜ ì¶œë ¥ì„ ì••ì¶•í•œë‹¤. ê¸°ì¡´ì—ëŠ” pooling unitì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í–ˆì§€ë§Œ, ë³¸ ë…¼ë¬¸ì—ì„œëŠ” pooling  unitì„ ê²¹ì¹˜ë„ë¡ ì„¤ì •í–ˆë‹¤. ì´ë¥¼ í†µí•´ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” íš¨ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆì—ˆë‹¤.
<br>

## | Reducing Overfitting

ìƒë‹¹í•œ ê³¼ì í•©ì´ ë°œìƒí•˜ì—¬ í•´ê²° ë°©ì•ˆì„ ëª¨ìƒ‰í–ˆë‹¤.

### Data Augmentation

ë°ì´í„° ìˆ˜ë¥¼ ëŠ˜ë ¤ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì—°ì‚°ëŸ‰ì´ ë§ì§€ ì•Šìœ¼ë©´ì„œ ë³„ë„ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ì§€ ì•Šì•„ë„ ë˜ëŠ” ë°©ë²•ì„ ì ìš©í–ˆë‹¤. 

1. ì´ë¯¸ì§€ ì´ë™(Image translation) ë° ì¢Œìš° ë°˜ì „(Horizontal reflection)
2. ì£¼ì„±ë¶„ ë¶„ì„(PCA)ì„ ì´ìš©í•œ RGB ê°’ ë³€ê²½
<br>

### Dropout
    
ì—¬ëŸ¬ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê²°í•©í•˜ë©´ ì„±ëŠ¥ì´ ì˜¬ë¼ê°€ì§€ë§Œ ë³´í†µ ì—°ì‚°ëŸ‰ë„ ì¦ê°€í•œë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤. ì´ëŸ° ê²½ìš°ì— ì ìš©í•˜ê¸° ì¢‹ì€ ë°©ë²•ì´ ë°”ë¡œ Dropoutì´ë‹¤.

Dropoutì€ 0.5ì˜ í™•ë¥ ë¡œ ì€ë‹‰ì¸µ ë‰´ëŸ°ì˜ ì¶œë ¥ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤. 0ìœ¼ë¡œ ì„¤ì •ëœ ë‰´ëŸ°ì€ forwardì™€ back propagation ê³¼ì •ì— ì°¸ì—¬í•˜ì§€ ì•ŠëŠ”ë‹¤. ê·¸ ê²°ê³¼ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ëŠ” ë§¤ë²ˆ ë‹¤ë¥¸ êµ¬ì¡°ë¥¼ ê°€ì§€ê² ì§€ë§Œ, ì„œë¡œ ê°€ì¤‘ì¹˜ëŠ” ê³µìœ í•œë‹¤. ì´ ë°©ë²•ì€ Robustí•œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì„ ê°€ì§„ë‹¤.

ë³¸ ë…¼ë¬¸ì— ë”°ë¥´ë©´, Test ì‹œì—ëŠ” Dropout ì—†ì´ ì „ì²´ ë‰´ëŸ°ì„ ì‚¬ìš©í–ˆì§€ë§Œ, ê²°ê³¼ì— 1/2ì„ ê³±í•´ì£¼ì—ˆë‹¤ê³  í•œë‹¤.


>**ì™œ ê°€ì¤‘ì¹˜ê°€ ê³µìœ ë˜ëŠ”ê°€** <br>
( *" ~ the neural network samples a different architecture, but **all these architecturses share weights**"* ) <br>
í•™ìŠµì„ ì§„í–‰í•˜ë©´ ë§¤ iterë§ˆë‹¤ dropoutí•˜ëŠ” ë‰´ëŸ°ì´ ë‹¬ë¼ì§„ë‹¤. ê·¸ëŸ°ë° í•œ iterì˜ ê°€ì¤‘ì¹˜ëŠ” ë‹¤ìŒ iterë¡œ ì „ë‹¬ë˜ê³ , ì—…ë°ì´íŠ¸ê°€ ë˜ë‹ˆê¹Œ ê²°êµ­ ëª¨ë“  êµ¬ì¡°ì˜ ê°€ì¤‘ì¹˜ë“¤ì´ ê³µìœ ëœë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.
> <br>

## | Details of learning

ìµœì í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œëŠ” Stochastic Gradient Descentë¥¼ ì‚¬ìš©í–ˆìœ¼ë©°, weight decayì˜ ì—­í• ì´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤ëŠ” ì ì„ ì•Œì•„ëƒˆë‹¤. 
<br>

## | Results

- ILSRVC-2010, 2012ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤.
- ê° GPUì˜ ì»¤ë„ì—ì„œ ë‹¤ë¥¸ íŠ¹ì§•ì„ í•™ìŠµí•˜ëŠ” ì–‘ìƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.    
- ì´ë¯¸ì§€ ì† ë¬¼ì²´ì˜ ìœ„ì¹˜ì— ìƒê´€ì—†ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
<br>

## | Discussions

- í¬ê³  ê¹Šì€ CNNì€ ì§€ë„ í•™ìŠµ(Supervised learning)ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
- í•˜ë‚˜ì˜ ë ˆì´ì–´ê°€ ì‚­ì œë˜ë©´ ì„±ëŠ¥ ì €í•˜ê°€ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•„ ê¹Šì´ê°€ ë§¤ìš° ì¤‘ìš”í•œ ìš”ì†Œì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.
<br>

