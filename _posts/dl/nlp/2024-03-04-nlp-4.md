---
title: "[NLP] Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU)"
header:
  #image: /assets/images/page-header-image.png
  #og_image: /assets/images/page-header-og-image.png
categories:
  - NLP
tags:
  - LSTM
permalink: /dl/nlp/4/
use_math : true
toc: true
toc_sticky : true
last_modified_at: 2024-03-04
---
**ğŸ§šğŸ»â€â™€ï¸ì°¸ê³ **<br>
ì´ í¬ìŠ¤íŠ¸ëŠ” [Boostcourseì˜ 'ìì—°ì–´ì²˜ë¦¬ì˜ ëª¨ë“  ê²ƒ'](https://www.boostcourse.org/ai330)ì„ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
{:.notice--blog-theme}

## | Long Short-Term Memory (LSTM)
### LSTM
LSTMì€ RNNì˜ gradient vanishing/explodingê³¼ long-term dependencyë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê³ ì•ˆëœ ë°©ë²•ì´ë‹¤.(RNNì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ [ì—¬ê¸°ë¡œ](https://codehyunn.github.io/dl/nlp/3/)) ì •ë³´ë¥¼ ë³€í˜•ì—†ì´ ë©€ë¦¬ê¹Œì§€ ì „ë‹¬í•˜ëŠ” ê²ƒì´ í•µì‹¬ ì•„ì´ë””ì–´ì¸ë°, ì´ë¥¼ ìœ„í•´ LSTMì—ì„œëŠ” ë³€í˜•í•˜ì§€ ì•Šì€ ì •ë³´ë¥¼ ë‹¤ìŒ stateë¡œ ì „ë‹¬í•˜ëŠ” **cell state**ë¥¼ ì‚¬ìš©í•œë‹¤.

$$ \begin{align} RNN & : h_t = f_W(h_{t-1}, x_t)\\
                 LSTM & : {(c_t, h_t)} = LSTM(c_{t-1}, h_{t-1}, x_t)
    \end{align} $$

![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/5306d1c8-c718-49d0-978b-893142896c6d){: .align-center}

ìœ„ì˜ ê·¸ë¦¼ì€ LSTMì˜ êµ¬ì¡°ë¥¼ ë‚˜íƒ€ë‚¸ ê·¸ë¦¼ì´ë‹¤. hidden state vectorë§Œ ë‹¤ìŒ ì‹œì ìœ¼ë¡œ ì „ë‹¬ë˜ëŠ” RNNê³¼ ë‹¬ë¦¬ LSTMì€ **cell state vector($$c_t$$)**ì™€ **hidden state vector($$h_t$$)**ê°€ ë‹¤ìŒ ì‹œì ìœ¼ë¡œ ì „ë‹¬ëœë‹¤. $$c_t$$ëŠ” ë³´ë‹¤ ì™„ì„±ëœ ì •ë³´ë¥¼ ë‹´ê³  ìˆìœ¼ë©°, ì´ë¥¼ ê°€ê³µí•˜ì—¬ $$h_t$$ë¥¼ ë§Œë“ ë‹¤. ì¦‰, $$h_t$$ëŠ” í•„í„°ë§ ëœ ì •ë³´ê°€ ë‹´ê¸´ ë²¡í„°ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ $$h_t$$ëŠ” output layerì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë˜ì–´ outputì„ ê³„ì‚°í•˜ëŠ” ë°ì— ì‚¬ìš©ëœë‹¤. 

### LSTMì˜ Gates
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/0953fbf1-fd28-462a-add1-56f6796a22f0){: .align-center}

LSTMì˜ êµ¬ì¡°ë¥¼ ìì„¸íˆ ë³´ë©´ ì´ 4ê°œì˜ ê²Œì´íŠ¸, **Input, Forget, Output, Gate gate**ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤. ì´ ê²Œì´íŠ¸ë“¤ì€ $$c_{t-1}$$ì„ ì ì ˆí•˜ê²Œ ë³€í™˜í•˜ì—¬ cell stateë¡œë¶€í„° ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ê°€ì ¸ì˜¬ì§€ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. 

ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ $$h_{t-1}, x_t$$ëŠ” ì„ í˜•ë³€í™˜ì„ ë§ˆì¹œ ë’¤ 4ê°œì˜ ë²¡í„°ë¡œ ë¶„í• ë˜ëŠ”ë°, ì´ ë²¡í„°ë“¤ì€ ê°ê° sigmoidë‚˜ tanh í•¨ìˆ˜ì™€ ì—°ì‚°ëœë‹¤. ì—°ì‚°ì„ ë§ˆì¹œ ë²¡í„°ë“¤ì€ ì •ë³´ ë°˜ì˜ ë¹„ìœ¨ê³¼ ê°™ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. ì´ê²Œ ë¬´ìŠ¨ ë§ì¸ê°€ ì‹¶ë‹¤ë©´ ì•„ë˜ì—ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì‚´í´ë³´ì. 

#### Forget gate

$${f_t = \sigma(W_f \cdot[h_{t-1}, x_t]+b_f)}$$

Forget gateëŠ” ì´ì „ ì‹œì ì—ì„œ ì „ë‹¬ ëœ ì •ë³´ ì¤‘ ì¼ë¶€ë¥¼ ì§€ì›Œë²„ë¦¬ëŠ”(ìŠì–´ë²„ë¦¬ëŠ”) ê²Œì´íŠ¸ì´ë‹¤. Forget gateì˜ ë²¡í„° $$f_t$$ëŠ” sigmoid í•¨ìˆ˜ì™€ ì—°ì‚°ëœ ë²¡í„°ë¡œ, 0-1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§„ë‹¤. ì´ ê°’ë“¤ì€ $${c_{t-1}}$$ì˜ ì •ë³´ ì¤‘ ì–´ëŠ ì •ë„ë¥¼ ê¸°ì–µí• ì§€ ê²°ì •í•˜ëŠ” í™•ë¥ ë¡œ ì‘ìš©í•˜ë©°, $${c_{t-1}}$$ê³¼ element-wiseë¡œ ê³±í•´ì§„ë‹¤.

#### Input gateì™€ Gate gate

$$ \begin{align} i_t & = \sigma(W_i \cdot[h_{t-1}, x_t]+b_i) \\
                 \tilde{C_t} & = tanh(W_c \cdot[h_{t-1}, x_t]+b_c) \\
                 C_t & = f_t \cdot C_{t-1} + i_t \cdot \tilde{C_t}
   \end{align} $$

Input gateì™€ Gate gateëŠ” í˜„ì¬ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ë°˜ì˜í• ì§€ ê²°ì •í•˜ëŠ” ê²Œì´íŠ¸ì´ë‹¤. Input gateì˜ ë²¡í„° $$i_t$$ëŠ” $$f_t$$ì™€ ë§ˆì°¬ê°€ì§€ë¡œ sigmoid í•¨ìˆ˜ë¥¼ í†µê³¼í•œ ë²¡í„°ì´ë‹¤. ê·¸ì™€ ë‹¬ë¦¬ Gate gateì˜ $$\tilde{C_t}$$ëŠ” tanh í•¨ìˆ˜ì™€ ì—°ì‚°ë˜ì–´ -1ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§„ë‹¤. ì´ ë‘ ë²¡í„°ë“¤ì€ element-wiseë¡œ ê³±í•´ì§ìœ¼ë¡œì¨ ì…ë ¥ëœ ì •ë³´ ì¤‘ì—ì„œ ê¸°ì–µí•  ì •ë³´ì˜ ì–‘ì„ ê²°ì •í•œë‹¤. ìµœì¢…ì ìœ¼ë¡œ ì´ì „ ì‹œì  ì •ë³´ ì¤‘ì—ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ë‚¨ê¸´ $$f_t \cdot C_{t-1}$$ì™€ ë”í•˜ì—¬ í˜„ì¬ ì‹œì ì˜ cell state vector $$C_t$$ë¥¼ ì™„ì„±í•œë‹¤.

ê·¸ëŸ¬ë‹ˆê¹Œ ìˆ˜ì‹ (5)ëŠ” {ì´ì „ ì‹œì  ì •ë³´ + í˜„ì¬ ì‹œì  ì •ë³´}ë¥¼ ë‚˜íƒ€ë‚¸ ì‹ì´ë¼ê³  ë³´ë©´ ëœë‹¤.
{:.notice}

#### Output gate 

$$ \begin{align} o_t &= \sigma(W_o \cdot[h_{t-1}, x_t]+b_o) \\
                 h_t & = o_t \cdot tanh(C_t)
   \end{align} $$

Output gateëŠ” $$h_t$$ë¥¼ ë§Œë“œëŠ” ë°ì— í™œìš©ëœë‹¤. sigmoid í•¨ìˆ˜ë¥¼ í†µí•´ ì—°ì‚°ëœ Output gateì˜ ë²¡í„°ëŠ” tanhë¥¼ í†µê³¼í•œ $$C_t$$ì„ ì¼ì •í•œ ë¹„ìœ¨ë§Œí¼ ì‘ê²Œ ë§Œë“ ë‹¤. ì´ ê³¼ì •ì„ í†µí•´ $$h_t$$ëŠ” $$C_t$$ì˜ í•„í„°ë§ ëœ ì •ë³´ë¥¼ ê°–ê²Œ ëœë‹¤. ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ $$h_t$$ëŠ” ë‹¤ìŒ ì‹œì ì´ë‚˜ output layerë¡œ ì „ë‹¬ëœë‹¤.

## | Gated Recurrent Unit (GRU)
GRUëŠ” LSTMì„ ê²½ëŸ‰í™”í•œ ëª¨ë¸ë¡œ, LSTMì— ë¹„í•´ ê³„ì‚° ì†ë„ê°€ ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ëŠ” ì ê²Œ ë“¤ì§€ë§Œ, ì„±ëŠ¥ì€ ë¹„ìŠ·í•˜ë‹¤ëŠ” ì¥ì ì„ ê°€ì§„ë‹¤. 

![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/4f2a9577-471a-47d4-a9e4-4e6fdab5ae9e){:.align-center}

GRUì˜ êµ¬ì¡°ëŠ” LSTMê³¼ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šë‹¤. ë‹¤ë§Œ LSTMê³¼ ë‹¬ë¦¬ hidden state vector í•˜ë‚˜ë§Œì„ í™œìš©í•˜ë©°, 2ê°œì˜ ê²Œì´íŠ¸(Update gate, Reset gate)ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” íŠ¹ì§•ì„ ê°€ì§„ë‹¤.

$$ \begin{align} z_t &= \sigma(W_z \cdot[h_{t-1}, x_t]) \\
                 r_t &= \sigma(W_r \cdot[h_{t-1}, x_t]) \\
                 \tilde{h_t} & = tanh(W \cdot[r_t\cdot h_{t-1}, x_t]) \\
                 h_t & = (1-z_t)\cdot h_{t-1} + z_t\cdot \tilde{h_t}
   \end{align} $$

ê²Œì´íŠ¸ì˜ ìˆ˜ê°€ ì¤„ì–´ë“¤ë©´ì„œ ìƒê¸´ ê°€ì¥ í° ì°¨ì´ëŠ”, ì´ì „ê³¼ í˜„ì¬ ì •ë³´ì˜ ê°€ì¤‘í‰ê· ìœ¼ë¡œ $$h_t$$ë¥¼ ì—°ì‚°í•œë‹¤ëŠ” ì ì´ë‹¤. ìˆ˜ì‹(11)ì€ [ì´ì „ ì‹œì ì˜ ì •ë³´ + í˜„ì¬ ì‹œì ì˜ ì •ë³´]ë¥¼ ê³„ì‚°í•˜ëŠ” ì‹ìœ¼ë¡œ LSTMì˜ ìˆ˜ì‹(5)ì™€ ê°™ì€ ì—­í• ì„ í•œë‹¤. LSTMì—ì„œëŠ” Input, Forget gateë¥¼ ì´ìš©í•˜ì—¬ ì—°ì‚°í–ˆì§€ë§Œ GRUì—ì„œëŠ” Update gate($$z_t$$) í•˜ë‚˜ë§Œìœ¼ë¡œ ë‘ ì •ë³´ì˜ ë°˜ì˜ ë¹„ìœ¨ì„ ê²°ì •í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ GRUëŠ” LSTMê³¼ ë¹„ìŠ·í•˜ë©´ì„œë„ ë‹¤ë¥´ê²Œ ì‘ë™í•œë‹¤.


## | Backpropagation in LSTM/GRU
RNNì€ ë§¤ ì‹œì ë§ˆë‹¤ ë™ì¼í•œ ê°€ì¤‘ì¹˜ê°€ ê³±í•´ì§€ê¸° ë•Œë¬¸ì— gradient vanishing/exploding ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤. ê·¸ëŸ¬ë‚˜ LSTMê³¼ GRUëŠ” ë§¤ë²ˆ ê³±í•´ì§€ëŠ” ê°€ì¤‘ì¹˜ê°€ ë‹¤ë¥´ê³ , í•„ìš”í•œ ì •ë³´ëŠ” ë”í•˜ê¸° ë•Œë¬¸ì— gradient ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•ŠëŠ”ë‹¤. ë˜, ë©€ë¦¬ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•´ì§€ë©´ì„œ long-term dependencyë„ ì–´ëŠ ì •ë„ í•´ê²°ë˜ì—ˆë‹¤.