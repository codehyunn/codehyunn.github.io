---
title: "[NLP] Bag-of-Words"
header:
  #image: /assets/images/page-header-image.png
  #og_image: /assets/images/page-header-og-image.png
categories:
  - NLP
tags:
  - Bag-of-Words
  - Naive Bayes
permalink: /dl/nlp/1/
use_math : true
toc: true
toc_sticky : true
last_modified_at: 2024-02-25
---
**ğŸ§šğŸ»â€â™€ï¸ì°¸ê³ **<br>
ì´ í¬ìŠ¤íŠ¸ëŠ” [Boostcourseì˜ 'ìì—°ì–´ì²˜ë¦¬ì˜ ëª¨ë“  ê²ƒ'](https://www.boostcourse.org/ai330)ì„ ë“£ê³  ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
{:.notice--blog-theme}

## | Bag-of-Words
Bag-of-WordsëŠ” NLP ë¶„ì•¼ì—ì„œ ë”¥ëŸ¬ë‹ ì´ì „ì— ë§ì´ ì‚¬ìš©ë˜ë˜ ê¸°ë²•ì´ë‹¤. ì´ë¦„ ê·¸ëŒ€ë¡œ ë¬¸ì¥ì—ì„œì˜ ë‹¨ì–´ë“¤ì„ ê°€ë°©ì— ë„£ì–´ ëª¨ì€ ê²ƒê³¼ ê°™ì€ ë°©ë²•ì´ë‹¤. ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ëŠ”ì§€ ì‚´í´ë³´ì.

### 1. Vocabulary ë§Œë“¤ê¸°
VocabularyëŠ” ì£¼ì–´ì§„ ë¬¸ì¥ë“¤ì— ë“±ì¥í•˜ëŠ” ëª¨ë“  ë‹¨ì–´ë“¤ì„ ëª¨ì€ ì§‘í•©ì´ë‹¤. í•œ ë‹¨ì–´ê°€ ì—¬ëŸ¬ë²ˆ ë“±ì¥í•˜ë”ë¼ë„ Vocabularyì—ëŠ” í•œë²ˆë§Œ ë“±ì¥í•˜ë„ë¡ êµ¬ì„±í•œë‹¤.

**ğŸ¨ì˜ˆì‹œ (1)**<br>
ì£¼ì–´ì§„ ë¬¸ì¥ : 'I like pizza', 'She loves this pizza'<br>
VocabularyëŠ” **{'I', 'like', 'pizza', 'she', 'loves', 'this'}** ì´ë‹¤.
{:.notice}

### 2. Vocabularyì˜ ë‹¨ì–´ë“¤ì„ one-hot vectorë¡œ ì¸ì½”ë”©í•˜ê¸°
VocabularyëŠ” ë²”ì£¼í˜• ë³€ìˆ˜(Categorical variable)ì´ë¯€ë¡œ ëª¨ë¸ í•™ìŠµì— í™œìš©í•˜ê¸°ì—” ë¶€ì í•©í•˜ë‹¤. ëŒ€ì‹  ë‹¨ì–´ë“¤ì„ **one-hot vector**ë¡œ ë³€ê²½í•´ì¤€ë‹¤. ì´ë•Œ, ë‹¨ì–´ ì‚¬ì´ì˜ ì˜ë¯¸ë‚˜ í‘œí˜„ì˜ ìœ ì‚¬ì„±ê³¼ëŠ” ìƒê´€ì—†ì´ ëª¨ë“  ë‹¨ì–´ ê°„ì˜ ê±°ë¦¬ê°€ $$\sqrt2$$ì´ê³ , ì½”ì‚¬ì¸ ìœ ì‚¬ë„ëŠ” 0ì„ì„ ê¸°ì–µí•´ë‘ì. ì´ ì ì´ ë°”ë¡œ ìš”ì¦˜ ë§ì´ ì‚¬ìš©ë˜ëŠ” word embeddingê³¼ ëŒ€ë¹„ë˜ëŠ” íŠ¹ì§•ì´ê¸° ë•Œë¬¸ì´ë‹¤.<br>

**ğŸ¨ì˜ˆì‹œ (2)**<br>
ì˜ˆì‹œ (1)ì˜ ë‹¨ì–´ë“¤ì„ one-hot vectorë¡œ ë§Œë“¤ì–´ë³´ì. <br>
I : **[1,0,0,0,0,0]**, like : **[0,1,0,0,0,0]**, pizza : **[0,0,1,0,0,0]**,<br>
she : **[0,0,0,1,0,0]**, loves : **[0,0,0,0,1,0]**, this : **[0,0,0,0,0,1]**<br>
{:.notice}

### 3. ë¬¸ì¥ì„ one-hot vectorì˜ í•©ìœ¼ë¡œ í‘œí˜„í•˜ê¸°
ë¬¸ì¥ì„ êµ¬ì„±í•˜ëŠ” ë‹¨ì–´ë“¤ì˜ one-hot vectorë¥¼ ë”í•˜ì—¬ ë¬¸ì¥ì„ í‘œí˜„í•œë‹¤. <br>

**ğŸ¨ì˜ˆì‹œ (3)**<br>
'She loves this pizza'ë¥¼ one-hot vectorì˜ í•©ìœ¼ë¡œ í‘œí˜„í•´ë³´ì.<br>
she + loves + this + pizza = [0,0,0,1,0,0] + [0,0,0,0,1,0] + [0,0,0,0,0,1] + [0,0,1,0,0,0] = **[0,0,1,1,1,1]**
{:.notice}

## | Naive Bayes Classifier
NaiveBayes ClassifierëŠ” Bag-of-Wordsë¡œ í‘œí˜„í•œ ë¬¸ì„œë“¤ë¡œ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ ì‚¬ìš©ëœ ë°©ë²•ì´ë‹¤. ë¨¼ì € ë¬¸ì„œì™€ í´ë˜ìŠ¤ì— ëŒ€í•œ Bayes' Ruleì„ ì•Œì•„ë³´ë ¤ê³  í•˜ëŠ”ë°, ê·¸ì „ì— ì¡°ê±´ë¶€ í™•ë¥ (Conditional probability)ë¶€í„° ê°„ë‹¨í•˜ê²Œ ì“± ë³´ê³ ê°€ì.

### ì¡°ê±´ë¶€ í™•ë¥ 
ì£¼ì–´ì§„ ì‚¬ê±´ì´ ì¼ì–´ë‚¬ì„ ë•Œ ë‹¤ë¥¸ ì‚¬ê±´ì´ ì¼ì–´ë‚  í™•ë¥ ì„ ì˜ë¯¸í•œë‹¤. ë‹¤ë¥¸ ì–´ë–¤ ì‚¬ê±´ì„ A, ì£¼ì–´ì§„ ì‚¬ê±´ì„ Bë¼ê³  í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ í‘œê¸°í•  ìˆ˜ ìˆë‹¤.

$$P(A|B) = \frac{P(A\cap B)}{P(B)}$$

### Bayes' Rule
ì¡°ê±´ë¶€ í™•ë¥ ì˜ ìˆ˜ì‹ì„ ì •ë¦¬í•˜ë©´ ì•„ë˜ ì‹ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. 

$$P(A\cap B) = P(A|B)P(B) = P(B|A)P(A)$$

ê·¸ë¦¬ê³  ì´ ì‹ì„ ì´ìš©í•˜ì—¬ ì¡°ê±´ë¶€ í™•ë¥ ì˜ ìˆ˜ì‹ì„ ë°”ê¿”ë³´ë©´, 

$$P(A|B) = \frac{P(A\cap B)}{P(B)} = \frac{P(B|A)P(A)}{P(B)} = \frac{P(A|B)P(B)}{P(B)}$$

ì—¬ê¸°ì—ì„œ Bê°€ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ì„ ë•Œì˜ Aì˜ í™•ë¥ ì¸ $${P(A)}$$ë¥¼ ì‚¬ì „ í™•ë¥ (Prior), Bê°€ ì¼ì–´ë‚¬ì„ ë•Œì˜ Aì˜ í™•ë¥ ì¸ $${P(A\mid{B})}$$ëŠ” ì‚¬í›„ í™•ë¥ (Posterior)ë¼ê³  í•˜ë©° $${P(B\mid{A})}$$ëŠ” ê°€ëŠ¥ë„(likelihood), $${P(B)}$$ëŠ” ì¦ê±°(Evidence)ë¼ê³  í•œë‹¤.

### Bayes' Rule for Documents and Classes
Bayes' Ruleì„ ì–´ë–¤ ë¬¸ì„œ dì™€ í´ë˜ìŠ¤ cì— ëŒ€í•´ ì ìš©í•˜ë©´ ì´ë ‡ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. ì´ë•Œ, ë¬¸ì„œ dë¥¼ êµ¬ì„±í•˜ëŠ” ë‹¨ì–´ë¥¼ $$w$$ë¼ê³  í•˜ì.

$$ \begin{align} C_{MAP} & = argmax_{c\in C}{P(c|d)}\\
                         & = argmax_{c\in C}{\frac{P(d|c)P(c)}{P(d)}} \\
                         & = argmax_{c\in C}{P(d|c)P(c)} \\
                         & = argmax_{c\in C}{P(w_1, w_2, \cdots, w_n | c)P(c)}
   \end{align} $$ 

(1)ì˜ MAPëŠ” *'Maximum A Posterior'*ì˜ ì•½ìì´ë‹¤. ì¦‰ $$C_{MAP}$$ëŠ” ì‚¬í›„ í™•ë¥ ì´ ìµœëŒ€ê°’ì„ ê°€ì§€ëŠ” í´ë˜ìŠ¤ì¸ ì •ë‹µì— ê°€ì¥ ê°€ê¹Œìš´ í´ë˜ìŠ¤ë¥¼ ì˜ë¯¸í•œë‹¤. ë² ì´ì¦ˆ ì •ë¦¬ì— ë”°ë¼ì„œ ì‹ì„ ë³€ê²½í•˜ì˜€ëŠ”ë°, (2)ì—ì„œ ë¬¸ì„œ dê°€ ë°œìƒí•  í™•ë¥ ì¸ $$P(d)$$ëŠ” ìƒìˆ˜ì—¬ì„œ ë¬´ì‹œí•˜ì˜€ë‹¤. (3)ì˜ í´ë˜ìŠ¤ cì— ëŒ€í•´ dê°€ ë“±ì¥í•  í™•ë¥  $${P(d\mid{c})}$$ì€ dë¥¼ êµ¬ì„±í•˜ëŠ” ëª¨ë“  ë‹¨ì–´ì¸ wê°€ ë“±ì¥í•  í™•ë¥ ê³¼ ê°™ë‹¤ê³  ë³¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ cì— ëŒ€í•´ wê°€ ë“±ì¥í•  í™•ë¥ ì˜ ê³±ìœ¼ë¡œ í‘œí˜„í•˜ì˜€ë‹¤.

**ğŸ¨ì˜ˆì‹œ (4)**<br>
Test dataì˜ Classë¥¼ ì˜ˆì¸¡í•´ë³´ì.<br>
{:.notice}

| Train/Test | Document(d) | Documnet(w) | Class |
| :--------: | :---------: | :---------: | :---: | 
| Train | 1 | Image reconition uses convolutional neural networks | CV |
| Train | 2 | Transformer can be used for image classification task | CV |
| Train | 3 | Language modeling uses transformer | NLP |
| Train | 4 | Document classification task is language task | NLP |
| Test | 5 | Classification task uses transformer | ?? | 
{:.notice}

í´ë˜ìŠ¤ ë³„ ë°œìƒ í™•ë¥  :  $$ P(C_{CV}) = \frac{2}{4} = \frac{1}{2}, P(C_{NLP}) = \frac{2}{4} = \frac{1}{2} $$ <br><br>
Bag-of-Wordsë¥¼ ì‚¬ìš©í•˜ì—¬ Test dataì˜ ë‹¨ì–´ë“¤ì— ëŒ€í•œ ì¡°ê±´ë¶€ í™•ë¥ ($$P(w|c)$$)ì„ êµ¬í•˜ë©´, <br>
$$P(w_{classification}|c_{CV}) = \frac{1}{10}, P(w_{task}|c_{CV}) = \frac{1}{10}, P(w_{uses}|c_{CV}) = \frac{1}{10}, P(w_{transformer}|c_{CV}) = \frac{1}{10}$$ <br>
$$P(w_{classification}|c_{NLP}) = \frac{1}{13}, P(w_{task}|c_{NLP}) = \frac{2}{13}, P(w_{uses}|c_{NLP}) = \frac{1}{13}, P(w_{transformer}|c_{NLP}) = \frac{1}{13}$$ <br><br>
ì´ì œ ìœ„ì˜ ë‘ í™•ë¥ ê°’ë“¤ì„ ê³±í•˜ì—¬ ìµœì¢… í™•ë¥ ì„ ê³„ì‚°í•˜ê³ , í° ê°’ì„ ê°€ì§€ëŠ” í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ë©´ ëì´ë‹¤. (ê³„ì‚°ì€ .. pass .. )<br>
$$P(c_CV|d_5) = P(C_{CV}) * P(w_{classification}|c_{CV}) * P(w_{task}|c_{CV}) * P(w_{uses}|c_{CV}) * P(w_{transformer}|c_{CV})$$
$$P(c_NLP|d_5) = P(C_{NLP}) * P(w_{classification}|c_{NLP}) * P(w_{task}|c_{NLP}) * P(w_{uses}|c_{NLP}) * P(w_{transformer}|c_{NLP})$$
{:.notice}
