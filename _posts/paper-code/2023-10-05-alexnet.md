---
title: "[PyTorch ë…¼ë¬¸ êµ¬í˜„] AlexNet : ImageNet Classification with Deep Convolutional Neural Networks"
header:
  #image: /assets/images/page-header-image.png
  #og_image: /assets/images/page-header-og-image.png
categories:
  - Paper-Code
tags:
  - paper
  - code
  - CNN
  - alexnet
last_modified_at: 2023-10-05
use_math : true
---
PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ AlexNetì„ êµ¬í˜„í•´ë³´ì•˜ë‹¤.<br>ë…¼ë¬¸ ë¦¬ë·°ëŠ” [ì—¬ê¸°](https://codehyunn.github.io/paper-review/alexnet/)ğŸ‘€ğŸª„

## | ëª¨ë¸ êµ¬ì¡° íŒŒì•…í•˜ê¸°
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/7dd979c5-2b8c-49c0-bfe9-239716fa1d77){: .align-center}
    
êµ¬í˜„í•˜ê¸°ì— ì•ì„œ ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë ˆì´ì–´ ë³„ êµ¬ì¡°ë¥¼ ì¬êµ¬ì„±í•´ë³´ì•˜ë‹¤.

| Layer | Kernel (ê°œìˆ˜) | Activation fn. | Normalization | Feature map (output) |
| :---: | :-----------: | :-----------: | :------------: | :------------------: |
| Input | - | - | - | 227x227x3 |
| Conv1 | 11x11x3 (96), stride 4 | ReLU | LRN | 55x55x96 |
| MaxPool | 3x3, stride 2 | - | - | 27x27x96 | 
| Conv2 | 5x5x48 (256), stride 1, padding 2 | ReLU | LRN | 27x27x256 |
| MaxPool | 3x3, stride 2 | - | - | 27x27x96 |
| Conv3 | 3x3x256 (384), stride 1, padding 1 | ReLU | - | 13x13x384 | 
| Conv4 | 3x3x192 (384), stride 1, padding 1 | ReLU | - |	13x13x384 | 
| Conv5 |	3x3x192 (256), stride 1, padding 1 | ReLU |	- |	13x13x256 |
| MaxPool | 3x3, stride 2 | - | - | 6x6x256 | 
| FC1 | - | ReLU | - | 4096 | 
| FC2 | - | ReLU | - | 4096 |
| FC3 | - | ReLU | - | 1000<br>(í´ë˜ìŠ¤ ê°œìˆ˜) | <br>

Convolution layerì˜ paddingê³¼ strideê°€ ì£¼ì–´ì§€ì§€ ì•Šì€ ê²½ìš°, ì•„ë˜ì˜ ì‹ì„ í™œìš©í•˜ì—¬ ê³„ì‚°í–ˆë‹¤. ì—¬ê¸°ì„œ inputê³¼ outputì€ ê°ê°ì˜ feature map í¬ê¸°ë¥¼ ì˜ë¯¸í•œë‹¤. ë§Œì•½ ê³„ì‚° ê²°ê³¼ê°€ ì •ìˆ˜ë¡œ ë”± ë–¨ì–´ì§€ì§€ ì•ŠëŠ”ë‹¤ë©´ ë²„ë¦¼ìœ¼ë¡œ ê³„ì‚°í•˜ë©´ ëœë‹¤.

$$
\frac{input + 2 * padding - kernel}{stride}+1=output
$$

ì˜ˆë¥¼ ë“¤ì–´, Conv3ì˜ strideì™€ paddingì„ êµ¬í•´ë³´ì.<br> input = 13, output = 13, kernel = 3 ì´ë¼ê³  ì£¼ì–´ì¡Œìœ¼ë¯€ë¡œ ì´ ê°’ë“¤ì„ ì‹ì— ëŒ€ì…í•˜ê³  ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

$$\frac{13 + 2 * padding - 3}{stride}+1=13$$

$$10+2*padding=12*stride$$

ê¹”ë”í•˜ê²Œ ê°’ì´ êµ¬í•´ì§€ì§„ ì•Šì•˜ì§€ë§Œ, ì§ê´€ì ìœ¼ë¡œ padding=1, stride=1ì´ë©´ ì‹ì´ ì„±ë¦½í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.

## | ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
ë…¼ë¬¸ì—ì„  ImageNet ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ, ì´ë²ˆì—” ê°„ë‹¨í•˜ê²Œ CIFAR 10 ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ í–ˆë‹¤. CIFAR-10 ë°ì´í„°ì…‹ì€ 60000ì¥ìœ¼ë¡œ ì´ë£¨ì–´ì§„ 32x32 í¬ê¸°ì˜ RGB ì´ë¯¸ì§€ ë°ì´í„°ì´ë©° 10ê°œì˜ í´ë˜ìŠ¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. 

![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/1bdfe351-b8f2-44db-bde4-fd4635a8685d){: .align-center}

ì „ì²˜ë¦¬ë¡œëŠ” ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ 227x227ë¡œ ë§ì¶”ëŠ” resizeì™€ ë°ì´í„° ì…‹ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ í™œìš©í•œ normalizationì„ ì ìš©í–ˆë‹¤.

```python
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((227,227)),
    transforms.Normalize(mean = [0.4914, 0.4822, 0.4465],
                         std = [0.2023, 0.1994, 0.2010])
])
```
ê°‘ìê¸° ë“±ì¥í•œ ë°ì´í„° ì…‹ì˜ í‰ê· (mean)ê³¼ í‘œì¤€í¸ì°¨(std) ê°’ì€ ì•„ë˜ì˜ ì½”ë“œë¥¼ í†µí•´ êµ¬í–ˆë‹¤.<br> ì½”ë“œëŠ” [ê¾¸ì¤€í¬ë‹˜ì˜ í‹°ìŠ¤í† ë¦¬](https://eehoeskrap.tistory.com/463)ë¥¼ ì°¸ê³ í–ˆë‹¤.

```python
#import torch
#import torchvision
#import torchvision.datasets as datasets
#from tqdm import tqdm

dataset = datasets.CIFAR10("./data", download=True, train=True, transform=transforms.ToTensor())
full_loader = torch.utils.data.DataLoader(dataset, shuffle=False)

mean = torch.zeros(3)
std = torch.zeros(3)

for image, _label in tqdm(full_loader) :
  for i in range(3) :
    mean[i] += image[:,i,:,:].mean()
    std[i] += image[:,i,:,:].std()

# div_() = inplace version of div()
mean.div_(len(dataset))
std.div_(len(dataset))

print('\n')
print(f'mean : {mean}')
print(f'std : {std}')
```
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/e31deea3-4ad7-4941-8cac-17bc6c42fc5e)

> **Torch Tensor vs. Numpy ndarray**<br>
(H = height, W = weight, C = channel, B = batch size)<br>
torch.tensor: C x H x W (3ì°¨ì›) or B x C x H x W (4ì°¨ì›)<br>
numpy.ndarray : H x W x C
>

ì½”ë“œë¥¼ ë³´ë‹¤ë³´ë‹ˆê¹Œ í…ì„œì˜ ì±„ë„ì´ ì˜ë¯¸í•˜ëŠ” ë°”ê°€ í—·ê°ˆë ¤ì„œ ì •ë¦¬í•´ë´¤ë‹¤.<br> 
í˜„ì¬ ì´ë¯¸ì§€ëŠ” 4ì°¨ì› í…ì„œì´ê³ , ìš°ë¦¬ëŠ” ì±„ë„ ë³„ë¡œ mean, std ê°’ì„ êµ¬í•´ì•¼í•˜ë¯€ë¡œ í…ì„œì˜ ë‘ ë²ˆì§¸ ì¸ë±ìŠ¤ì— ëŒ€í•´ ì—°ì‚°ì„ ìˆ˜í–‰í–ˆë‹¤.

ì´ì œ train, test setì„ ë¶ˆëŸ¬ì˜¤ê³  data loaderì— ë„£ì–´ì£¼ë©´ ëœë‹¤. ì§ !
```python
#import torchvision
#import torchvision.datasets as datasets
#import torchvision.transforms as transforms

train = datasets.CIFAR10(root='./data', train=True, transform=transform, download=False)
test = datasets.CIFAR10(root='./data', train=False, transform=transform, download=False)

print('train: \n', train, '\n')
print('test: \n', test, '\n')
```
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/5c8835cf-e391-4013-a1fd-493e8975f8ce)

```python
BATCH_SIZE = 128

train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=BATCH_SIZE, shuffle=True)
```
## | ëª¨ë¸ êµ¬í˜„í•˜ê¸°
ìœ„ì—ì„œ ì‘ì„±í•œ í‘œ ê·¸ëŒ€ë¡œ! ë ˆì´ì–´ë¥¼ ìŒ“ì•„ì£¼ì.

```python
class AlexNet(nn.Module) :

  """
    AlexNet Class
  """

  def __init__(self, num_classes) :
    super().__init__()

    self.num_classes = num_classes

    self.conv1 = nn.Sequential(
        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),
        nn.ReLU(),
        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),
        nn.MaxPool2d(kernel_size=3, stride=2)
    )

    self.conv2 = nn.Sequential(
        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),
        nn.ReLU(),
        nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),
        nn.MaxPool2d(kernel_size=3, stride=2)
    )

    self.conv3 = nn.Sequential(
        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),
        nn.ReLU()
    )

    self.conv4 = nn.Sequential(
        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),
        nn.ReLU()
    )

    self.conv5 = nn.Sequential(
        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=3, stride=2)
    )

    self.fc1 = nn.Sequential(
        nn.Dropout(),
        nn.Linear(in_features=6*6*256, out_features=4096),
        nn.ReLU()
    )

    self.fc2 = nn.Sequential(
        nn.Dropout(),
        nn.Linear(in_features=4096,out_features=4096),
        nn.ReLU()
    )

    self.fc3 = nn.Linear(in_features=4096, out_features=self.num_classes)

  def forward(self, x) :
    # convolution laters
    x = self.conv1(x)
    x = self.conv2(x)
    x = self.conv3(x)
    x = self.conv4(x)
    x = self.conv5(x)

    # fc layers
    x = x.view(-1, 256*6*6) # ì´ê±° ì•ˆí•´ì£¼ë©´ ì˜¤ë¥˜ë‚˜ìš” (flatten)
    x = self.fc1(x)
    x = self.fc2(x)
    x = self.fc3(x)
    return x
```

ì²˜ìŒì— í…ì„œë¥¼ 1ì°¨ì›ìœ¼ë¡œ í´ì£¼ëŠ” ê³¼ì • ì—†ì´ ëª¨ë¸ êµ¬í˜„ì„ ëëƒˆì—ˆë‹¤. ê·¸ëŸ°ë° ëª¨ë¸ì„ ëŒë¦¬ë ¤ê³  í•˜ë‹ˆê¹Œ ì•„ë˜ì˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ”ê±° ì•„ë‹Œê°€ (â€¢á·„à¡‡â€¢á·…)
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/a0bb7bb1-f33c-45d3-abfb-93a248f3b69b){:.align-center}
ê³¼ì¥í•´ì„œ í•œ ì‹œê°„ ì •ë„ ì°¾ì•„ë³´ë‹¤ê°€ ê²¨ìš° ê¹¨ë‹«ê³  í•´ê²°í–ˆë‹¤.<br>
**ìŠì§€ ë§ì. FC layer ì „ì— í…ì„œë¥¼ 1ì°¨ì›ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤.**

## | ëª¨ë¸ í™•ì¸í•˜ê¸°
ì´ì œ torchsummaryë¡œ ëª¨ë¸ì„ ì˜ ì‘ì„±í–ˆëŠ”ì§€ í™•ì¸í•´ë³´ë©´ !
```python
import torchsummary

NUM_CLASSES = 10

model = AlexNet(NUM_CLASSES)
model.to(device)

torchsummary.summary(model, input_size=(3,227,227), device='cuda')
```
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/4da150de-6a86-4306-8f61-873311a27722){:.align-center}
ì™„ë²½í•˜ë‹¤.

## | ëª¨ë¸ í•™ìŠµí•˜ê¸°
ë°ì´í„°ë„ ë¶ˆëŸ¬ ì™”ê³ , ëª¨ë¸ë„ êµ¬í˜„í–ˆìœ¼ë‹ˆê¹Œ ì´ì œ í•™ìŠµë§Œ í•˜ë©´ ëœë‹¤.<br>
ì¼ë‹¨ í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œëŠ” ë¶„ë¥˜ ë¬¸ì œì´ë¯€ë¡œ ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” Cross Entropy Lossë¥¼ ì‚¬ìš©í–ˆê³ , OptimizerëŠ” ë…¼ë¬¸ì—ì„œ ì–¸ê¸‰í•œ ê·¸ëŒ€ë¡œ ì„¤ì •í–ˆë‹¤. EpochëŠ” ë‚´ ë§˜ëŒ€ë¡œ 10ìœ¼ë¡œ ì„¤ì •í–ˆë‹¤.

```python
EPOCHS = 10
criterion = nn.CrossEntropyLoss()
optimizer = SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0005)
```

```python
def model_train(model, train_loader, criterion, optimizer, device) :
  model.train()
  for epoch in range(EPOCHS) :
    train_loss_sum = 0
    train_n_total, train_n_corr = 0, 0

    for iter, (img, label) in enumerate((tqdm(train_loader))) :
      img, label = img.to(device), label.to(device)

      # gradient reset
      optimizer.zero_grad()

      # forward pass
      pred = model.forward(img)

      # calculate loss
      loss = criterion(pred, label)

      # backpropagate, calculate derivative
      loss.backward()

      # optimizer update, gradient update
      optimizer.step()

      train_loss_sum += loss.item()

      _, y_pred = pred.max(dim=1)
      train_n_total += img.size(0)
      train_n_corr += (y_pred == label).sum().item()

    train_loss_avg = train_loss_sum/len(train_loader)
    train_acc = train_n_corr/train_n_total

    print(f'Epoch: {epoch+1}/{EPOCHS}, train loss : {train_loss_avg}, train acc : {train_acc}')

  print('Done')
```
> **zero_grad() ?**<br>
PyTorchëŠ” backpropagation ë‹¨ê³„ì—ì„œ gradientë¥¼ ëˆ„ì í•˜ì—¬ ë”í•œë‹¤. ê·¸ëŸ¬ë‚˜ íŒŒë¼ë¯¸í„°ëŠ” í˜„ì¬ ë¯¸ë¶„ê°’ì„ ì´ìš©í•˜ì—¬ ì—†ë°ì´íŠ¸ ëœë‹¤. ëˆ„ì ëœ ë¯¸ë¶„ê°’ì„ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ì— ì‚¬ìš©í•œë‹¤ë©´ ë¶„ëª…íˆ ì˜¤ë¥˜ê°€ ë°œìƒí•  ê²ƒì´ë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ zero_grad()ë¡œ ë§¤ iterë§ˆë‹¤ gradientë¥¼ ì´ˆê¸°í™” í•´ì¤€ë‹¤.
>

ì´ì œ í•™ìŠµì„ ëŒë ¤ë³´ì.
```python
model_train(model, train_loader, criterion, optimizer, device)
```
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/92538b59-0744-44de-a148-bfd73197bb78){:.align-center}

ì˜¤... ì„±ëŠ¥ì´ ë„ˆë¬´ ë³„ë¡œì—¬ì„œ ê¹œì§ ë†€ëë‹¤ ê’°â¤ê’± ì—í¬í¬ ìˆ˜ê°€ ë„ˆë¬´ ì ì—ˆë˜ ê±¸ê¹Œ?<br>ì¡°ê¸ˆ ë‹¹í™©ìŠ¤ëŸ¬ì› ì§€ë§Œ ê·¸ë˜ë„ êµ¬í˜„ì„ í•´ë´¤ë‹¤ëŠ” ì ì— ì˜ì˜ë¥¼ ë‘ê¸°ë¡œ í–ˆë‹¤.

## | ëª¨ë¸ í…ŒìŠ¤íŠ¸í•˜ê¸°
ë§ˆì§€ë§‰ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì.
```python
def model_test(model, test_loader, criterion, device) :
  model.eval()
  with torch.no_grad() :
    loss_sum = 0
    n_total, n_corr = 0, 0

    for iter, (img, label) in enumerate(tqdm(test_loader)) :
      img, label = img.to(device), label.to(device)

      pred = model.forward(img)

      _, y_pred = pred.max(dim=1)
      n_corr += (label == y_pred).sum().item()
      n_total += img.size(0)

      loss = criterion(pred, label)
      loss_sum += loss

    loss_avg = loss_sum/len(test_loader)
    acc = n_corr/n_total

    print(f'\nLoss : {loss_avg}, Acc : {acc}')
```
```python
model_test(model, test_loader, criterion, optimizer, device)
```
![image](https://github.com/codehyunn/codehyunn.github.io/assets/87523224/27cd9f4c-dd1e-4717-a633-ca1cd11df863)

ì—­ì‹œ ì •í™•ë„ê°€ ì•„ì‰½ë‹¤. <br>
ì´ë ‡ê²Œ AlexNet êµ¬í˜„ ë° í•™ìŠµ ë!